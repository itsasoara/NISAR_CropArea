{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88be1e38-00b8-41ca-9927-8b5fcccdc21c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a id=\"TOP\"></a>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/6/60/NISAR_artist_concept.jpg\" width=150/><img src=\"https://upload.wikimedia.org/wikipedia/commons/9/9b/NISAR_Mission_Logo.png\" width=200/> \n",
    "\n",
    "***\n",
    "\n",
    "# NASA ISRO Synthetic Aperture Radar Mission\n",
    "## Combined Algorithm Theoretical Basis Document and Jupyter Notebook for <br> *Active Crop Area*\n",
    "\n",
    "Authors: Jessica Martinez, Alex Christensen, Paul Siqueira <br>\n",
    "Microwave Remote Sensing Laboratory <br>\n",
    "University of Massachusetts -- Amherst <br>\n",
    "Date: 2025-02-11 <br>\n",
    "Last updated: 2025-August <br>\n",
    "\n",
    "### Summary\n",
    "This notebook describes the ATBD for generating an agricultural crop area product from NISAR time series data stacks. The algorithm is designed to meet the Level 2 Science requirements for detecting active crop area. This notebook constitutes a combination of formulating the theoretical basis for the NISAR active crop area algorithm that is based on the coefficient of variation and an implementation of the algorithm in executable python code.\n",
    "\n",
    "This particular notebook contains two parts that are combined into one notebook.  These are\n",
    "<ol>\n",
    "    <li>The Coefficient of Variation (CV) Python code, and</li>\n",
    "    <li>The USDA Cropland Data Layer (CDL)</li>\n",
    "</ol>\n",
    "Although not required to implement the NISAR Active Crop Area algorithm, the CDL is provided here to give an example how external data about the location of active crops can be used to optimally determine the threshold that can be applied to the CV for determining active crop area, and also used as a means for evaluating the algorithm.  For regions outside of the US (for example) where the CDL is not available, a similar landcover classification could be used, or one created from available optical data. <br>\n",
    "\n",
    "\n",
    "<br>The NISAR requirement for Active Crop Area is: <br>\n",
    "\n",
    "> *Requirement (L2-SCI-679):* <br> After the first year of operation, the NISAR Project shall measure crop area at 1-hectare resolution every 3 months with a classification accuracy of 80%.\n",
    "\n",
    "### Overview of the Coefficient of Variation\n",
    "Python code to implement coefficient of variation for crop/non-crop classification using a time series stack of SAR images. The notebook statistically calculates the CV across the time series stack and pixels in the resulting CV output are classified as “crop” or “non-crop” based on a threshold provided, or specified by the user. Pixels classified as water using a watermask derived from radar cross-section (RCS) values are removed prior to classification, due to the inherent variability of radar returns from water surfaces that make them inconsistent with the coefficient of variation (CV) patterns of non-cropland covers and prone to misclassification.\n",
    "\n",
    "This notebook supports either the use of the USDA Cropland Data Layer (CDL) (which has been provided in the repository for use in this notebook) or external sources of labeled crop/non crop polygons which can be generated using high-resolution optical imagery of field-based methods such as windshield surveying. The labeled crop/non-crop validation data are used to calibrate and assess the classification threshold to improve classification results. The accuracy of the classification is evaluated against this data, and the results are exported as a Geotiff. \n",
    "\n",
    "\n",
    "\n",
    "Coefficient of Variation is calculated by: Standard Deviation/Mean\n",
    "\n",
    "\n",
    "Datasets needed:\n",
    "\n",
    "    Timeseries of SAR imagery\n",
    "    \n",
    "    CDL available at https://nassgeodata.gmu.edu/CropScape/\n",
    "\n",
    "### Use conda environment:\n",
    "`NISAR_L3_CropArea`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afc5e604-96a6-4ba6-b86c-e2787865a71c",
   "metadata": {},
   "source": [
    "<a id=\"SEC_0.2\"></a>\n",
    "###  &emsp; Data Flow Diagram \n",
    "![NISAR_ATBD_crops_dataflow.png](NISAR_ATBD_crops_dataflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70bfab4-48c5-4872-af92-c85bfe1867a0",
   "metadata": {},
   "source": [
    "# 0 &emsp; Project Setup <a class=\"anchor\" id=\"first\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1e24eb-32db-484d-9db3-c56665618909",
   "metadata": {},
   "source": [
    "## 0.1  &emsp; Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a986c0b-d271-4e0a-929f-a15d377f1897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from osgeo import gdal, osr, ogr\n",
    "import subprocess\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import sys\n",
    "from pandas import DataFrame\n",
    "from IPython.display import Image\n",
    "import sklearn  # imported from scikit-learn\n",
    "from sklearn import metrics\n",
    "from matplotlib.pyplot import figure\n",
    "from matplotlib.colors import ListedColormap\n",
    "from ipywidgets import interactive\n",
    "from rasterio.plot import show_hist\n",
    "from rasterio.enums import ColorInterp\n",
    "from rasterio.enums import Resampling\n",
    "import datetime\n",
    "from datetime import date\n",
    "from datetime import datetime, UTC\n",
    "import math\n",
    "os.environ['GDAL_DATA'] = os.popen('gdal-config --datadir').read().rstrip() # resolves gdal directory value error\n",
    " \n",
    "from pathlib import Path\n",
    "import io\n",
    "import boto3\n",
    "import rasterio\n",
    "import zipfile\n",
    "import h5py\n",
    "from pyproj import CRS\n",
    "import geopandas as gpd\n",
    "import copy\n",
    "import asf_search as asf\n",
    "import earthaccess \n",
    "import json\n",
    "from getpass import getpass\n",
    "import requests\n",
    "import s3fs\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from tqdm.notebook import tqdm\n",
    "gdal.UseExceptions()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ca533a-a866-4724-a35e-82b3a9ab00ba",
   "metadata": {},
   "source": [
    "## 0.2  &emsp; Choose AOI and working directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62017d5-2e26-4ad3-ac21-e8cc1980f20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = Path(os.path.dirname(os.getcwd()))\n",
    "print(main_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0fca93-06ad-4d4a-ad77-4b014e098aa1",
   "metadata": {},
   "source": [
    "This notebook and it's repository have been set up to provide user's with data and classification parameters for Tifton, GA. With \"demo\" set as \"True\", this notebook can be fully self-contained and run completley through. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e5a914-b8ac-4889-b10b-fc4429191086",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = True\n",
    "if demo:\n",
    "    aoi = 'tifton'\n",
    "    which_pol = 'HHHH'\n",
    "else:\n",
    "    aoi = input('What site?')\n",
    "    which_pol = input('What polarization? [HHHH or HVHV]')\n",
    "    box_left, box_top, box_right, box_bottom = [input('Define AOI West boundary?: '),\n",
    "                                                input('Define AOI North boundary?: '),\n",
    "                                                input('Define AOI East boundary?: '),\n",
    "                                                input('Define AOI South boundary?: ')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0e415a-b7e2-4aa5-bc08-8f784c3e87eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ancillary_dir = main_dir / 'ancillary_data'\n",
    "aoi_dir = main_dir / aoi \n",
    "crop_dir = aoi_dir / 'crops'\n",
    "GCOV_dir = aoi_dir / 'GCOV'\n",
    "TMP_dir = aoi_dir / 'TMP'\n",
    "\n",
    "Path(ancillary_dir).mkdir(parents = True, exist_ok = True)\n",
    "Path(aoi_dir).mkdir(parents = True, exist_ok= True)\n",
    "Path(crop_dir).mkdir(parents = True, exist_ok = True)\n",
    "Path(GCOV_dir).mkdir(parents = True, exist_ok = True)\n",
    "Path(TMP_dir).mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "print(aoi_dir)\n",
    "print(crop_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0756163-e9f0-4cfd-81bc-d21b1b51abb1",
   "metadata": {},
   "source": [
    "\n",
    "# 1 &emsp; Get Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece94a40-b2de-46c6-aaae-5be942a2c8d8",
   "metadata": {},
   "source": [
    "<a id=\"SEC_1.1\"></a>\n",
    "## 1.1  &emsp; Get GCOV Data\n",
    "\n",
    "A pre-launch stack of sample GCOV products are provided for Tifton, GA.\n",
    "\n",
    "Post-launch NISAR GCOV products will be available through ASF DAAC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311d4961-c5a3-4b8c-8a4e-ade654a1edc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if demo:\n",
    "    gcov_url = ('s3://nisar-public-ebd/ATBD/ecosystems/croparea/sites/%s/*/*/*' %(aoi))\n",
    "    s3 = s3fs.S3FileSystem(anon=True,endpoint_url='https://s3.us-west-1.wasabisys.com')\n",
    "    all_GCOV_data = ['s3://' + k  for k in s3.glob(gcov_url)]\n",
    "\n",
    "else:\n",
    "    auth = earthaccess.login()\n",
    "    s3cred = auth.get_s3_credentials(endpoint=\"https://nisar.asf.earthdatacloud.nasa.gov/s3credentials\")\n",
    "    results = earthaccess.search_data(short_name = 'NISAR_L2_GCOV_BETA_V1', \n",
    "                                        # temporal = ('2023-07-01 00:00:00', '2023-08-31 23:59:59'), # can also specify by time\n",
    "                                        # granule_name = '*T00888*', # here we filter by files with CRID value of *T00888*\n",
    "                                        bounding_box = (box_left, box_bottom, box_right, box_top )\n",
    "                                       )\n",
    "    ## Get URLS for search results\n",
    "    all_GCOV_data = [earthaccess.results.DataGranule.data_links(x, access ='direct')[0] for x in results if earthaccess.results.DataGranule.data_links(x, access ='direct')[0].endswith('.h5')]\n",
    "\n",
    "    s3 = s3fs.S3FileSystem(anon = False, key=s3cred['accessKeyId'], \n",
    "                           secret = s3cred['secretAccessKey'],\n",
    "                           token = s3cred['sessionToken'],\n",
    "                           client_kwargs ={'region_name': 'us-west-2'})\n",
    "all_GCOV_data = sorted(all_GCOV_data)\n",
    "print(\"number of available scenes:\", len(all_GCOV_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b43c24-b083-4736-9699-64a4f96cdc7c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_GCOV_data_links = glob.glob(str(aoi_dir/'ATBD_CROPS*-urls.txt'))[0]\n",
    "# with open(all_GCOV_data_links, \"r\") as f:\n",
    "#     all_GCOV_data = [line.strip() for line in f if line.strip() and '.h5' in line]\n",
    "#     print(\"number of avaliable_scenes:\", len(all_GCOV_data))\n",
    "#     for i in range(len(all_GCOV_data)):\n",
    "#         print(i, all_GCOV_data[i].split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51758bcc-1963-4630-a5fc-3e1310e98562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if dir_type =='local':\n",
    "#     all_GCOV_data_links = glob.glob(str(aoi_dir/'ATBD_CROPS*-urls.txt'))[0]\n",
    "#     with open(all_GCOV_data_links, \"r\") as f:\n",
    "#         all_GCOV_data = [line.strip() for line in f if line.strip() and '.h5' in line]\n",
    "#         print(\"number of avaliable_scenes:\", len(all_GCOV_data))\n",
    "#         for i in range(len(all_GCOV_data)):\n",
    "#             print(i, all_GCOV_data[i].split('/')[-1])\n",
    "# else:\n",
    "#     auth = earthaccess.login()\n",
    "\n",
    "#     results = earthaccess.search_data(short_name = 'NISAR_L2_GCOV_BETA_V1', \n",
    "#                                         # temporal = ('2023-07-01 00:00:00', '2023-08-31 23:59:59'), # can also specify by time\n",
    "#                                         # granule_name = '*T00888*', # here we filter by files with CRID value of *T00888*\n",
    "#                                         bounding_box = (box_left, box_top, box_right, box_bottom )\n",
    "#                                        )\n",
    "#     ## Get URLS for search results\n",
    "#     all_GCOV_data = [earthaccess.results.DataGranule.data_links(x, access ='direct')[0] for x in results if earthaccess.results.DataGranule.data_links(x, access ='direct')[0].endswith('.h5')]\n",
    "\n",
    "#     print(\"number of available scenes:\", len(all_GCOV_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa766efe-92a9-4d21-958f-82ec8db7a4d0",
   "metadata": {},
   "source": [
    "<a id=\"SEC_1.4\"></a>\n",
    "## 1.2  &emsp; Select Images to Include in Time-Series Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7452c2-5ecf-4abc-910c-42047c234fa2",
   "metadata": {},
   "source": [
    "\n",
    "Creates a time-series stack of the SAR imagery\n",
    "\n",
    "The time-series of SAR images is nominally meant to be downloaded from an instrument data archive. The time series stack provided in the repository has already been co-registered for the area of interest. This data is NISAR-simulated from ALOS-1 PALSAR data to serve as an example pre-launch. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864005cb-e56b-437d-bed1-a486a41d3c28",
   "metadata": {},
   "source": [
    "**The NISAR mission will measure crop area every 3 months, for which CV is caculated within the bracketed dates of:**  <br>\n",
    "- January 1 - March 31<br>\n",
    "- April 1- June 30 <br>\n",
    "- July 1- September 30 <br>\n",
    "- October 1- December 31 <br>\n",
    "-in addition to the entire year. <br>\n",
    "\n",
    "\n",
    "**Selection of which images to include in the time series stack can capture one of these three month periods or use all avaliable scenes. For the demo, the pre-determined threshold for Tifton evaulates all avaliable time series dates within the 2022 year.** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400e763f-07f3-4f78-8767-bd78a7faa662",
   "metadata": {},
   "source": [
    "**Note:** in Python, 0 serves as the first element when indexing. Meaning, if the number of avalible scenes you want to use is '50', specifying an index of 0:49 will select the 50 available scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93afbfc7-b3af-4049-b6ea-46713eae6c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "if demo: \n",
    "    indices = '0:9'\n",
    "else:\n",
    "    indices = input('which GCOV files should be used (see Section 1.1 list for numbers)? ex: 0-1, 0, 1, 5, 1:5 inclusive')\n",
    "    \n",
    "if ':' in indices:\n",
    "    indices2 = list(range(int(indices.split(':')[0]), int(indices.split(':')[1])+1))\n",
    "elif '-' in indices:\n",
    "    indices2 = list(range(int(indices.split('-')[0]), int(indices.split('-')[1])+1))\n",
    "elif ',' in indices:\n",
    "    indices2 = []\n",
    "    num = indices.split(',')\n",
    "    for n in range(0,len(num)):\n",
    "        indices2.append(int(num[n]))\n",
    "else:\n",
    "    print('index type not recognized, please rerun the cell')\n",
    "        \n",
    "\n",
    "## If you don't want to use all of the images, choose which indices to use now. \n",
    "# indices = range(0,19)\n",
    "print(indices2)\n",
    "time_series_length = len(indices2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bd5028-c7b4-47da-b841-eb669cab046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dates of observation (HH and HV):\")\n",
    "date_array = []\n",
    "SAR_images = []\n",
    "for ii in indices2:\n",
    "    datestr = all_GCOV_data[ii].split('/')[-1].split('_')[11]\n",
    "    date_obj = pd.to_datetime(datestr)\n",
    "    print('%03d %s' %(ii, date_obj))\n",
    "    date_array.append(date_obj)\n",
    "    SAR_images.append(all_GCOV_data[ii])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efffff46-377e-43c0-af57-7e0723274c10",
   "metadata": {},
   "source": [
    "**Based on selected indices, define the seasonal time interval, to be used for later defined file naming conventions**<br>\n",
    "format= MMYY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c56bcf-5ec0-464c-87b9-731605dc460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the first MMYY and last MMYY used in the time series through regular expression\n",
    "\n",
    "first_datestr = str(SAR_images[0])\n",
    "last_datestr = str(SAR_images[-1])\n",
    "\n",
    "first_datestr_MMYY = re.search(r'_(\\d{4})(\\d{2})\\d{2}T', first_datestr)\n",
    "last_datestr_MMYY = re.search(r'_(\\d{4})(\\d{2})\\d{2}T', last_datestr)\n",
    "\n",
    "if first_datestr_MMYY :\n",
    "    mm1 = first_datestr_MMYY.group(2)\n",
    "    yy1 = first_datestr_MMYY.group(1)[2:] # last two digits of the year\n",
    "    l3_start_date = mm1 + yy1\n",
    "else:\n",
    "    print(\"An error occured\")\n",
    "\n",
    "if last_datestr_MMYY:\n",
    "    mm2 = last_datestr_MMYY.group(2)\n",
    "    yy2 = last_datestr_MMYY.group(1)[2:]\n",
    "    l3_end_date = mm2 + yy2\n",
    "else:\n",
    "    print(\"An error occured\")\n",
    "    \n",
    "print(l3_start_date)\n",
    "print(l3_end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaf75f8-2a96-4528-974e-534f041ebe96",
   "metadata": {},
   "source": [
    "<a id=\"SEC_1.3\"></a>\n",
    "## 1.3  &emsp; Read in data from GCOV HDF5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e63f05d-0b0e-4d5d-bbe7-cca681f60dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all h5 files\n",
    "h5_files = [h5py.File(s3.open(k, \"rb\")) for k in SAR_images]\n",
    "gcov_filenames = [k.filename.strip('<').strip('>').split('/')[-1] for k in h5_files]\n",
    "gcov_dates = [ (str(k.split('_')[11][:4]) + '-' + str(k.split('_')[11][4:6]) + '-' + str(k.split('_')[11][6:8])) for k in gcov_filenames]\n",
    "num_files = len(h5_files)\n",
    "gcov_filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d04d87-a4e3-4d20-9a71-3d1ea971e66d",
   "metadata": {},
   "source": [
    "<a id=\"SEC_1.4\"></a>\n",
    "## 1.4  &emsp; Build data arrays of all GCOVs in the time series stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b90622-b53b-485b-aba6-6c3dbbcf39e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_x = [f['science']['LSAR']['GCOV']['grids']['frequencyA']['xCoordinates'][()] for f in h5_files]\n",
    "ds_y = [f['science']['LSAR']['GCOV']['grids']['frequencyA']['yCoordinates'][()] for f in h5_files]\n",
    "ds_epsg = [f['science']['LSAR']['GCOV']['grids']['frequencyA']['projection'][()].item() for f in h5_files]\n",
    "ds_sigma0 = [f['science']['LSAR']['GCOV']['grids']['frequencyA'][which_pol][()] for f in h5_files] \n",
    "\n",
    "[f.close() for f in h5_files];\n",
    "\n",
    "a = np.array(ds_sigma0, dtype = float)\n",
    "num_dates = len(ds_sigma0)\n",
    "print(\"\\nNumber of dates in time series analysis:\", num_dates)\n",
    "tqdm.write(\"✅ Success!\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db38cfa-eba7-4cae-a4b0-9e2d8b57dbfa",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 1.5  &emsp; Plot SAR Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f46d7e-e19e-4e8a-989d-aded8e2d4a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = plt.get_cmap('Greys_r')\n",
    "plt.rcParams['figure.figsize'] = (20,8)\n",
    "for i in range(0,min(4,len(a))):\n",
    "    ax = plt.subplot(2,2,i+1)\n",
    "    plt.imshow(10*np.log10(a[i,:,:]),vmin = -22,vmax = -5,interpolation ='nearest',cmap = cmp)\n",
    "    plt.colorbar(label = 'dB')\n",
    "    ax.axes.get_xaxis().set_ticks([])\n",
    "    ax.axes.get_yaxis().set_ticks([])\n",
    "    plt.title(date_array[i],fontsize=8) \n",
    "    plt.tight_layout()\n",
    "    \n",
    "print(which_pol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cfc21a-344a-4afe-8422-ea48a2e29a28",
   "metadata": {},
   "source": [
    "## 1.6  &emsp; Get geocoding information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ea1f83-c9a2-477f-bde0-abe42259cc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = ds_x[0].shape[0]\n",
    "height = ds_y[0].shape[0]\n",
    "transform = rasterio.Affine(ds_x[0][1] - ds_x[0][0], 0.0, ds_x[0][0] - ((ds_x[0][1] - ds_x[0][0])/2), 0.0, ds_y[0][1] - ds_y[0][0], ds_y[0][0] - ((ds_y[0][1] - ds_y[0][0]) / 2))\n",
    "crs = rasterio.CRS.from_epsg(ds_epsg[0])\n",
    "EPSG = ds_epsg[0]\n",
    "x_posting = transform[0]\n",
    "y_posting = transform[0]\n",
    "minx = ds_x[0][0]\n",
    "miny = ds_y[0][-1]\n",
    "maxx = ds_x[0][-1]\n",
    "maxy = ds_y[0][0]\n",
    "\n",
    "meta = {'driver': 'GTiff', \n",
    "        'dtype': 'uint8', \n",
    "        'nodata': 0, \n",
    "        'width': width, \n",
    "        'height': height, \n",
    "        'count': 1, \n",
    "        'crs': crs, \n",
    "        'transform': transform,\n",
    "        'tiled': True,\n",
    "        \"driver\": \"COG\",\n",
    "        \"compress\": \"LZW\",   # Apply LZW compression\n",
    "        \"blockxsize\": 512,   # Tile size\n",
    "        \"blockysize\": 512,\n",
    "        \"overviews\": [2, 4, 8, 16],  # Pyramid overviews\n",
    "        \"BIGTIFF\": \"YES\",\n",
    "        'interleave': 'band'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874e5eba-ab53-45e4-bf2b-5318fa789984",
   "metadata": {},
   "source": [
    "# Get water mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a56ff67-6512-402f-8cb4-9db5cf396751",
   "metadata": {},
   "source": [
    "## 1.7  &emsp; Radar cross section  watermask generation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd68e17-3f09-440a-991c-c70380833a10",
   "metadata": {},
   "source": [
    "This section generates a watermask from the Radar Cross Section (RCS) values across the observed time series. Water has a high variation measurement not comparable to the CV values of other non-cropland land covers and is often missclassified because of this. Through implementation of a threshold based approach, pixels in the time series stack are classified as water if their RCS value is equal to or below the user-defined threshold more than 75% of the time (across the time series stack), ensuring that the high variation of water remains accounted for to reduce the risk of potential misclassification.  <br>\n",
    ">**Note:** generation of the RCS watermask will require some investigation of scene statistics as well as visual inspection of the time series stack for adequate selection of a threshold. Water bodies are typically visually notable in SAR imagery, due to the nature for which they interact with the microwave pulses transmitted by the SAR system (i.e. NISAR). Water typically behaves similarly to a mirror when recieving the transmitted pulses, reflecting the energy away from the sensor. Thus, since the recieved pulse is reflected away, very little signal reflects directly back to the sensor, resulting in distinguisably lower backscatter values and a visually darker presence in the image compared to neighboring and surronding land cover.\n",
    ">> The threshold for distinguising water pixels will vary depending both on the SAR imagery used and the temporal period of the time series stack. A very loose reference RCS reference range for water is -15 dB to -30 dB, with the understanding that the threshold value may end up being outside of this range. \n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a1224f-4bff-463c-a79c-5e7e13137140",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_arr = 10 * np.log10(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7474f59c-974a-4215-8d8d-4814cd5d899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Peaks in the RCS histogram can be referenced for selection of the watermask threshold \n",
    "print('Values in dB')\n",
    "print(\"Pixel Standard Deviation: Min = %s, Max = %s, Mean = %s\" %(round(np.nanmin(db_arr),6),round(np.nanmax(db_arr),6),round(np.nanmean(db_arr),6)))\n",
    "\n",
    "plt.figure(figsize = (9,6))\n",
    "show_hist(db_arr,bins = 50, title = \"Histogram of %s RCS values\" %(which_pol))  # this is the only routine that uses rasterio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d59501-9808-4c02-b202-c0abdee62dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define RCS threshold and reclassify time series based on threshold\n",
    "water_number = 111\n",
    "watermask_cmap = plt.cm.colors.ListedColormap([\"#ffffff\", \"#496fa2\"])\n",
    "water_thresh = -16.5\n",
    "masked_ts_stack = np.where(db_arr <= water_thresh,1,0)\n",
    "\n",
    "# aggregate the water mask over time, if a pixel is classified as water based on the threshold used at least 75% of the time, \n",
    "# it is classified as water across the entire time series stack \n",
    "rcs_watermask = (np.sum(masked_ts_stack, axis = 0) > (db_arr.shape[0] * 0.75)).astype(int)\n",
    "\n",
    "# reclassify the watermask to match the classification values of the CDL (water= 111)\n",
    "watermask = np.copy(rcs_watermask)\n",
    "watermask[np.where(rcs_watermask == 1)] = 111\n",
    "\n",
    "# get the number of pixels masked and not masked\n",
    "rcs111 = np.count_nonzero(watermask == water_number)\n",
    "print(\"Number of water pixels:\", rcs111)\n",
    "\n",
    "rcs0 = np.count_nonzero(watermask == 0)\n",
    "print(\"Number of pixels for classification:\", rcs0)\n",
    "    \n",
    "# visually inspect the watermask, and adjust threshold if needed\n",
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "fig.tight_layout()\n",
    "cax = ax.imshow(watermask, interpolation ='nearest', cmap = watermask_cmap)\n",
    "ax.set_title(\"Water Mask\")\n",
    "cbar = fig.colorbar(cax, ticks = [0,111], fraction = 0.046 * watermask.shape[0] / watermask.shape[1],pad = 0.04)\n",
    "cbar.ax.set_yticklabels(['Non-Water', 'Water'])\n",
    "plt.ylabel('Y Coordinates (meters)', labelpad=10)\n",
    "plt.xlabel('X Coordinates (meters)', labelpad=10)\n",
    "print('Water pixels are marked as blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600c7db8-8463-4292-b290-73cbe13d2cf4",
   "metadata": {},
   "source": [
    "# 2 &emsp; Coefficient of Variation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a91fed-768d-4566-a821-9de9f03ff559",
   "metadata": {},
   "source": [
    "## 2.1 &emsp; Calculating the CV on the SAR Timeseries Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88190dd6-7580-4980-87e2-cdb98d9f3078",
   "metadata": {},
   "source": [
    "The equation for the Coefficient of Variation (CV) is:\n",
    "\n",
    "CV = Standard Deviation / Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4478bf-cd94-4abc-9bb3-494915e55b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Calculate the mean for the time stack of images\n",
    "    mean = np.mean(a, axis = 0)\n",
    "\n",
    "    # Calculate the standard deviation for the time stack of images\n",
    "    std = np.std(a, axis = 0)\n",
    "\n",
    "    # Calculate the coefficient of variation for the time stack of images \n",
    "    CV = (std/mean)#*mask\n",
    "except ValueError as e:\n",
    "    print('caculation of CV failed', e)\n",
    "else:\n",
    "    print('✅ CV successfully caculated')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bb0bb6-be9d-4141-9e2d-55fcbbd1dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.set_cmap('Reds_r')\n",
    "plt.rcParams['figure.figsize'] = (20,5)\n",
    "plt.imshow(10*np.log10(mean), vmin = -22, vmax = -10, interpolation ='nearest');\n",
    "plt.colorbar(fraction = 0.046*mean.shape[0] / mean.shape[1], pad = 0.04);\n",
    "plt.ylabel('Y Coordinates (meters)', labelpad=10)\n",
    "plt.xlabel('X Coordinates (meters)', labelpad=10)\n",
    "plt.title('Mean of Radar-Cross Section(dB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f27a2e-c333-45e3-a741-40092360f649",
   "metadata": {},
   "source": [
    "## 2.2 &emsp; Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfe5fb6-59d9-45ce-ad18-f690a0776fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Values in dB')\n",
    "print(\"Pixel Standard Deviation: Min = %s, Max = %s, Mean = %s\" %(round(np.nanmin(std),6),round(np.nanmax(std),6),round(np.nanmean(std),6)))\n",
    "print(\"Pixel Coefficient of Variation: Min = %s, Max = %s, Mean = %s\" %(round(np.nanmin(CV),6),round(np.nanmax(CV),6),round(np.nanmean(CV),6)))\n",
    "\n",
    "show_hist(np.clip(CV,0,1),bins = 50,title = \"Histogram of %s CV values\" %(which_pol))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56308cfe-26dd-46e1-b8d4-9c92b70f8495",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(std, vmin = 0, vmax = 0.02, interpolation = 'nearest', cmap = cmp);\n",
    "plt.colorbar(fraction = 0.046*std.shape[0]/std.shape[1], pad=0.04);\n",
    "plt.ylabel('Y Coordinates (meters)', labelpad = 10)\n",
    "plt.xlabel('X Coordinates (meters)', labelpad = 10)\n",
    "plt.title('Standard deviation of Radar Cross Section (magnitude)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660b0e21-35fe-45fd-92b5-8d420c67994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(CV, vmin = 0.05, vmax = 1, interpolation ='nearest', cmap = 'Reds_r');\n",
    "plt.colorbar(fraction = 0.046*CV.shape[0] / CV.shape[1], pad=0.04);\n",
    "plt.ylabel('Y Coordinates (meters)', labelpad = 10)\n",
    "plt.xlabel('X Coordinates (meters)', labelpad = 10)\n",
    "plt.title('Coefficient of Variation');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb3eae0-7992-444d-b90f-6e952ac58e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del std,mean,a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c049409d-a64f-4895-a30a-00212f249546",
   "metadata": {},
   "source": [
    "## 2.3&emsp; Export CV and then crop CV to extent of AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b045673c-da2b-46fb-ba2a-08b59ab51da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today().strftime(\"%Y%m%d\")\n",
    "if demo:\n",
    "    aoi_prefix = 'TFGA'\n",
    "else: \n",
    "    aoi_prefix = input('first four intuitive letters of site name, in uppercase  (i.e. TFGA for Tifton, GA):')\n",
    "\n",
    "CV_prefix = \"NISAR_CV_%s_40_A_CROP_%s_%s_%s_001_%s.tif\" %(str(which_pol[:-2]), l3_start_date, l3_end_date, aoi_prefix, today)\n",
    "\n",
    "try: \n",
    "    with rasterio.open(crop_dir / CV_prefix, 'w', **meta) as dst:\n",
    "        dst.write(CV,indexes = 1)  \n",
    "        print(\"✅ Success!\")\n",
    "except Exception as e:\n",
    "    print('An error occured: {e}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181eaee3-af45-4b32-8765-c5f03e47cb06",
   "metadata": {},
   "source": [
    "# 3 &emsp; Generate L3 Crop Area Product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd8777c-54c3-4d98-8198-ac1998394c47",
   "metadata": {},
   "source": [
    "## 3.1 &emsp; Define threshold to classify crop area \n",
    "**Where:**\n",
    ">CV pixels >= threshold are classified as \"crop\" <br>\n",
    ">CV pixels < threshold are classified as \"non-crop\" <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98245ffb-6093-43b1-a368-60b790c58ca8",
   "metadata": {},
   "source": [
    "A pre-calibrated threshold for the example Tifton,GA data set within this repo has been provided.  Here, the ideal threshold was derived by Youden's J-Index, a summary measure representing the maximum difference between the true positive rate and false positive rate between the Coefficient of Variation and the validation source (i.e the CDL). While the ROC curve technique offers a statistical guidance to a threshold with discriminatory ability between crop area and non-crop area, users can also provide their own threshold from a \"guess and check\" approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386b9614-a56f-4b82-aec6-fc5be38b5d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if demo:\n",
    "    best_thresh = 0.4\n",
    "    print(\"Threshold for crop/non-crop classification:\", best_thresh)\n",
    "else:\n",
    "    best_thresh = input(\"Threshold for classification?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66f7fd3-0a7b-4b96-915a-2e912b116bf4",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d445a7-4927-4008-8aeb-df2d02e98a0c",
   "metadata": {},
   "source": [
    "## 3.5 &emsp; Create crop/non-crop classification for the Youden's Index Optimal Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d75157a-895f-4a6e-a708-d1988c903033",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classify image using the Youden's Index Optimal Threshold\n",
    "CV_reclass_ideal = np.copy(CV)\n",
    "CV_reclass_ideal[np.where(CV_reclass_ideal >= best_thresh)] = 1\n",
    "CV_reclass_ideal[np.where(CV_reclass_ideal < best_thresh)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4e86ae-9fab-479b-94bc-7000697f542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply watermask to classified result\n",
    "# first reclassify the watermask, so that all water pixels have a value of 3\n",
    "watermask0 = copy.deepcopy(watermask)\n",
    "watermask0[np.where(watermask0 == 111)] = 3\n",
    "CV_reclass_ideal_w_h20 = np.subtract(CV_reclass_ideal,watermask0)\n",
    "\n",
    "\n",
    "# reclassify the final classification to reset the waterpixels to a value of 3 again \n",
    "CV_reclass_ideal_w_h20[np.where(CV_reclass_ideal_w_h20 == -3)] = 3\n",
    "CV_reclass_ideal_w_h20[np.where(CV_reclass_ideal_w_h20 == -2)] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0ce9aa-1e06-4b29-85eb-b3a813eac07f",
   "metadata": {},
   "source": [
    "### Visually inspect the classification before exporting and downsampling to hectare scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de436ff-3751-40bd-b27c-1e13da322630",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20,5))\n",
    "fig.tight_layout()\n",
    "l3_cmap = plt.cm.colors.ListedColormap([\"#ffffff\", \"#EDB218\", \"#496fa2\"])\n",
    "cax = ax.imshow(CV_reclass_ideal_w_h20, interpolation = 'nearest', cmap = l3_cmap)\n",
    "ax.set_title('Final CV Classification: %s' %(which_pol))\n",
    "cbar = fig.colorbar(cax, ticks = [0,1,3], fraction = 0.046 * CV_reclass_ideal_w_h20.shape[0] / CV_reclass_ideal_w_h20.shape[1],pad = 0.04)\n",
    "cbar.ax.set_yticklabels(['Non-Crop', 'Crop', 'Water'])\n",
    "plt.ylabel('Y Coordinates (meters)', labelpad = 10)\n",
    "plt.xlabel('X Coordinates (meters)', labelpad = 10)\n",
    "\n",
    "print('Crop pixels marked in yellow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cc6fba-161a-423a-96e7-dd4ca616272d",
   "metadata": {},
   "source": [
    "## 3.6 &emsp; Export the classified image as 20m, downsample to 1 Ha resolution and export final L3 classification product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66afa2f-c65f-44d1-ab4d-d8599b07abd5",
   "metadata": {},
   "source": [
    "Writes the array to a geotiff that is classified by the Youden's Index ideal threshold based on CV to the set output directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bfcd20-866c-4b77-a28b-7670c3e0304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classified_20m_prefix = \"%s_%s_%s_20m_classification.tif\" %(aoi_prefix, str(which_pol[:-2]), today)\n",
    "L3_prefix = \"NISAR_L3_%s_40_A_CROP_%s_%s_%s_001_%s.tif\" %(str(which_pol[:-2]), l3_start_date, l3_end_date, aoi_prefix, today)\n",
    "print(classified_20m_prefix)\n",
    "print(L3_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70f25ed-8f73-468e-9520-1b70f20761d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reclassify the classified image to match the proper crop l3 classification values \n",
    "# where: non_crop = 1, crop = 2, water =3\n",
    "\n",
    "l3_CV_reclass_ideal_w_h20= np.copy(CV_reclass_ideal_w_h20)\n",
    "l3_CV_reclass_ideal_w_h20[CV_reclass_ideal_w_h20 == 0] = 1\n",
    "l3_CV_reclass_ideal_w_h20[CV_reclass_ideal_w_h20 == 1] = 2\n",
    "print(np.unique(l3_CV_reclass_ideal_w_h20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5396f24-d4eb-4069-b9fe-f5aa608f9b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(TMP_dir / classified_20m_prefix, 'w', **meta) as dst:\n",
    "    dst.write(l3_CV_reclass_ideal_w_h20,indexes = 1)  \n",
    "   \n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "fig.tight_layout()\n",
    "cax = ax.imshow(CV_reclass_ideal_w_h20, interpolation = 'nearest', cmap = l3_cmap)\n",
    "ax.set_title('Classified Crop/Non-Crop Area (20m resolution) ')\n",
    "cbar = fig.colorbar(cax, ticks = [0,1,3], fraction = 0.046 * CV_reclass_ideal_w_h20.shape[0] / CV_reclass_ideal_w_h20.shape[1],pad = 0.04)\n",
    "cbar.ax.set_yticklabels(['Non-Crop', 'Crop', 'Water'])\n",
    "plt.ylabel('Y Coordinates (meters)', labelpad = 10)\n",
    "plt.xlabel('X Coordinates (meters)', labelpad = 10)\n",
    "\n",
    "\n",
    "print('Crop pixels marked in yellow (Non-crop = 1, Crop = 2, Water = 3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4519f9-ea6b-40df-a0f4-780bb6d52a44",
   "metadata": {},
   "source": [
    "## 3.7 &emsp; Downsample to the hectare scale for generation of the final L3 crop area product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edbbc9f-50f9-42cb-ae9b-35dc7ff2dca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_20m_files = sorted(glob.glob(str(TMP_dir / classified_20m_prefix)))\n",
    "for file in classified_20m_files:\n",
    "    classified_20m_filename = str(file)\n",
    "    classified_20m_file = gdal.Open(classified_20m_filename)\n",
    "    print(classified_20m_filename)\n",
    "\n",
    "try:\n",
    "    gdal.Warp(str(aoi_dir / L3_prefix), classified_20m_file, xRes = 100, yRes = 100, resampleAlg ='near', format = 'GTIFF')\n",
    "    #os.remove(str(TMP_dir/classified_20m_filename))\n",
    "    print(\"✅ Success!\")\n",
    "except Exception as e:\n",
    "    print('An error occured: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad73a5eb-f6db-447f-a42a-a6804f7d60f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "L3_product_file = glob.glob(str(aoi_dir / L3_prefix))\n",
    "for file in L3_product_file:\n",
    "    L3_product = str(file)\n",
    "    croparea_L3_classification = gdal.Open(L3_product).ReadAsArray()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "fig.tight_layout()\n",
    "cax = ax.imshow(croparea_L3_classification, interpolation ='nearest', cmap = l3_cmap)\n",
    "ax.set_title('Classified Crop/Non-Crop Area (1 Ha resolution)')\n",
    "cbar = fig.colorbar(cax, ticks = [0,1,3], fraction = 0.046*croparea_L3_classification.shape[0] / croparea_L3_classification.shape[1], pad = 0.04)\n",
    "cbar.ax.set_yticklabels(['Non-Crop', 'Crop', 'Water'])\n",
    "plt.ylabel('Y Coordinates (meters)', labelpad = 10)\n",
    "plt.xlabel('X Coordinates (meters)', labelpad = 10)\n",
    "\n",
    "print('Crop pixels marked in yellow (Non-crop = 1, Crop = 2, Water = 3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacec1e5-486c-4e7a-9a90-7719b4a7fdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    " ## A statistical summary of the number of Crop and Non-Crop pixels from the crop/non-crop classification \n",
    "\n",
    "l3_cropcount = np.count_nonzero(croparea_L3_classification == 2)\n",
    "l3_noncount = np.count_nonzero(croparea_L3_classification == 1)\n",
    "l3_watercount = np.count_nonzero(croparea_L3_classification == 3)\n",
    "l3_nodata_count = np.count_nonzero(croparea_L3_classification == 0)\n",
    "\n",
    "total = np.count_nonzero(croparea_L3_classification != 0)\n",
    "\n",
    "# finding the percent of pixels classified as crop area, non-crop area and water\n",
    "percent_l3_crop = round((l3_cropcount / total) * 100,2)\n",
    "print('% Crop',percent_l3_crop)\n",
    "percent_l3_noncrop = round((l3_noncount / total) * 100, 2)\n",
    "print('% Non-Crop',percent_l3_noncrop)\n",
    "percent_l3_water = round((l3_watercount/total) * 100,2)\n",
    "print('% Water', percent_l3_water)\n",
    "percent_l3_nodata = round((l3_nodata_count/total) * 100,2)\n",
    "print('% No Data', percent_l3_nodata)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecf0f51-f21f-4da0-88e2-7167cc771146",
   "metadata": {},
   "source": [
    "### **set up metadata parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec23e28-7bf3-4286-9bc7-533ea0ed361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sar_array = []\n",
    "for ii in indices2:\n",
    "    fp = all_GCOV_data[ii].split('/')[-1]\n",
    "    sar_array.append(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259dcc70-4ae4-4471-9544-cba4a6814d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_nisar_date = str(sar_array[0])\n",
    "last_nisar_date = str(sar_array[-1])\n",
    "\n",
    "source_collectiontime_last = re.findall(r\"\\d{8}T\\d{6}\", last_nisar_date)\n",
    "source_collectiontime_first = re.findall(r\"\\d{8}T\\d{6}\", first_nisar_date)\n",
    "\n",
    "print(source_collectiontime_last)\n",
    "print(source_collectiontime_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4663e6a-71e8-4cdf-9eae-4d010e30f67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define L3 color table (DN values mapped to RGB colors) \n",
    "color_table_1ha = {\n",
    "#no data\n",
    "    0: (255, 255, 255, 0),\n",
    "#non-crop\n",
    "    1: (255, 255, 255, 1),\n",
    "#crop\n",
    "    2: (237, 178, 24, 1),\n",
    "#wateer \n",
    "    3: (73, 111, 162, 1)\n",
    "    \n",
    "\n",
    "}\n",
    "    \n",
    "with rasterio.open(aoi_dir / L3_prefix, 'w', **meta) as dst:\n",
    "    dst.write(croparea_L3_classification,indexes=1)  \n",
    "    dst.write_colormap(1, color_table_1ha)\n",
    "    dst.colorinterp = [ColorInterp.palette]\n",
    "    # Create overviews (pyramids) for faster cloud visualization\n",
    "    overviews = [2, 4, 8, 16]  # Example downsampling levels\n",
    "    dst.build_overviews(overviews, Resampling.average)\n",
    "    # Update metadata\n",
    "    dst.update_tags(\n",
    "        AREA_OR_POINT = \"Area\",\n",
    "        CEOS_docid ='https://ceos.org/ard/files/PFS/SAR/v1.1/CEOS-ARD_PFS_Synthetic_Aperture_Radar_v1.1.pdf',\n",
    "        prod_name = 'CROP',\n",
    "        prod_processing_date = datetime.now(UTC).strftime(\"%Y%m%dT%H%M%S\"),\n",
    "        prod_software_version = \"1.0\",\n",
    "        prod_speckle_filter = \"FALSE\",\n",
    "        prod_type =\" SCIENCE \",\n",
    "        source_band_width = \"20\",\n",
    "        source_center_wavelength = \"0.238403545 m\",\n",
    "        source_collectiontime_last = source_collectiontime_last,\n",
    "        source_collectiontime_first = source_collectiontime_first,\n",
    "        source_data_access = \"ASF NASA/JAXA agreement\",\n",
    "        source_instrument = \"L-SAR\",\n",
    "        source_number_of_acquisitions = time_series_length,\n",
    "        source_pointing = \"left\",\n",
    "        source_pol = which_pol,\n",
    "        source_radar_az_looks = \"22\",\n",
    "        source_radar_range_looks = \"5\",\n",
    "        source_radar_band = \"L\",\n",
    "        source_radar_east_pixel_spacing = \"20\",\n",
    "        source_radar_look_look_direction = \"Ascending\",\n",
    "        source_radar_mode = \"polsar\",\n",
    "        source_radar_nes0 = \"-30\",\n",
    "        source_radar_north_pixel_spacing = \"100\",\n",
    "        source_radar_pointing = \"left\",\n",
    "        source_radar_pol = \"quad\",\n",
    "        source_radar_processing_facility = \"NASA Jet Propulsion Laboratory\",\n",
    "        source_radar_product_level = \"L2\",\n",
    "        source_radar_software_version = '83634531328a6b1fb3991f252a5c6d52b7a9ed4b',\n",
    "        source_satellite = 'NISAR',\n",
    "        stats_percDN0 = l3_nodata_count,\n",
    "        stats_percDN1 = l3_noncount,\n",
    "        stats_percDN2 = l3_cropcount,\n",
    "        stats_percDN3 = l3_watercount,\n",
    "        Classes = \"Described Below\",\n",
    "        DN3 = \"Water\",\n",
    "        DN2 = \"Active Crop\",\n",
    "        DN1 = \"Non-Crop\",\n",
    "        DN0 = \"No Data   (transparent)   \",\n",
    "    )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfc4c6a-dd21-47c3-ad15-8797e7cbaf83",
   "metadata": {},
   "source": [
    "# Optional: validation & accuracy assesment \n",
    "What follows below, demonstrates the validation and accuracy assesment process implemented to evaulate whether the produced crop area classification meets the NISAR L2 science requirement for active crop area. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4ddefe-5d95-43f5-9202-d8bddbfcabb3",
   "metadata": {},
   "source": [
    "## Define validation/training data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdece8e-32dd-41ac-8217-a6d161a0dc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_type = input('\"CDL\" or \"EXTERNAL SOURCE\":')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb3512d-424d-4fb7-936f-d4a1ed9d6763",
   "metadata": {},
   "source": [
    "# 4 &emsp; Validation Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21092b68-28cf-46c5-9e27-4fc1841af6f4",
   "metadata": {},
   "source": [
    ">**Note:** The data provided as part of this NISAR ATBD notebook for TIfton, GA includes a pre-downloaded, cropped and aligned Cropland Data Layer for which the notebook can be self-contained without any additional downloading or importing of other validation resources required. However, option for use of external validation data and functionality to download the CDL are also provided for circumstances where another area of interest is desired to be investigated. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb89d28-3091-4b8d-a9c4-11b5ec5fb358",
   "metadata": {},
   "source": [
    "## 4.1 &emsp; Download the Cropland Data Layer\n",
    "\n",
    "Having access to the Cropland Data Layer ([CDL](https://nassgeodata.gmu.edu/CropScape/); a landcover classification for the continental US) is not required for the Coefficient of Variation algorithm, it can be used as an input to determine the location of crops versus non-crops, and hence used to determine the best threshold for the NISAR Active Crop Area algorithm.  In locations where the CDL is not available, other products may be available (such as ESA's [GlobCover](http://due.esrin.esa.int/page_globcover.php) and [High Resolution Ground Cover](https://climate.esa.int/en/projects/high-resolution-land-cover/)), or derived independently from available high-resolution optical data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb27c79b-30a7-43ee-bfdd-b3e8cf3d5590",
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_data_type == 'CDL':\n",
    "    cdl_cmap = np.loadtxt(ancillary_dir / 'cdl_cmap.txt',dtype='float')\n",
    "    cdl_cmap = ListedColormap(cdl_cmap)\n",
    "\n",
    "    cdl_year = 2023\n",
    "    cdl_dir = ancillary_dir / 'cdl'\n",
    "    cdl_full_file = '%s_30m_cdls' %(cdl_year)\n",
    "    cdl_crop_file = '%s_CDL_%s.tif' %(aoi, cdl_year)  \n",
    "\n",
    "    if os.path.isfile(crop_dir/cdl_crop_file):\n",
    "         print(' %s cdl for %s exists already' %(cdl_year, aoi))\n",
    "\n",
    "    else: \n",
    "        if os.path.isfile(cdl_dir/ (cdl_full_file +'.tif'))==False:\n",
    "            if os.path.isfile(cdl_dir / (cdl_full_file + '.zip'))==False:\n",
    "                url = 'https://www.nass.usda.gov/Research_and_Science/Cropland/Release/datasets/%s.zip' %(cdl_full_file)\n",
    "                !wget -P {cdl_dir} -q {'https://www.nass.usda.gov/Research_and_Science/Cropland/Release/datasets/%s.zip'%(cdl_full_file)}\n",
    "            with zipfile.ZipFile(cdl_dir / (cdl_full_file + '.zip'), 'r') as zip_ref:\n",
    "                zip_ref.extractall(cdl_dir)\n",
    "                os.remove(cdl_dir/ (cdl_full_file + '.zip'))\n",
    "        else:\n",
    "            print('%s CDL is already downloaded in: %s' %(cdl_year, cdl_dir))\n",
    "\n",
    "        CDL_full = glob.glob(str(cdl_dir / (cdl_full_file + '.tif')))[0]\n",
    "else:\n",
    "     print('%s is specified as the training/validation source' %(training_data_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45cfa32-732c-4467-b355-937b89cea30e",
   "metadata": {},
   "source": [
    "> **Note:** The native spatial resolution of the Cropland Data Layer (from 2008-2023) is 30m. For the 2024 CDL, this has increased to 10m. In order to harmonize the use of the CDL with SAR data, consistent spatial resolution and grid alignment is fundamental for acheiving accurate classification results. The cell below implements the gdalwarp tool to both crop the CDL to the extent of the Area of Interest and resample the data to match the spatial resolution of the SAR time series stack (20m). The CDL is clipped to the extent of the AOI by the *-te* flag, which uses the bounding box extent defined by the AOI geojson file above, while the *-tap* flag (target aligned pixels) ensures the the output grid is properly aligned with the reference SAR image. The *-tr* flag resamples the spatial resolution of the CDL, by setting the target pixel size. In this case, this is defined by the predefined x and y positing (20m).<br>\n",
    ">> Further information about gdal-warp can be found by following the provided link below, which leads to gdal's documentation page: <br>\n",
    "https://gdal.org/en/stable/programs/gdalwarp.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087133ec-14a9-4053-bec1-9fc2fc298b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_data_type == 'CDL':\n",
    "    if os.path.isfile(crop_dir/cdl_crop_file):\n",
    "        print('cdl has already been extracted to extent of %s, skip to cell below' %(aoi)) \n",
    "    else: \n",
    "        os.system('gdalwarp -overwrite -s_srs epsg:5070 -t_srs epsg:%s -tap -tr %s %s -te %s %s %s %s %s %s' \n",
    "                  %(EPSG,transform[0],transform[0],ds_x[0][0],ds_y[0][-1],ds_x[0][-1],ds_y[0][0],CDL_full,crop_dir/cdl_crop_file))\n",
    "else:\n",
    "    print('%s is specified as the training/validation source' %(training_data_type))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b3ab4d-ce1b-484e-88a5-48a32a00006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dimensions of CDL\n",
    "if training_data_type == 'CDL':\n",
    "    first_raster_CDL = gdal.Open(str(crop_dir/cdl_crop_file))\n",
    "    rows1 = first_raster_CDL.RasterYSize\n",
    "    cols1 = first_raster_CDL.RasterXSize\n",
    "\n",
    "\n",
    "    # Open CDL\n",
    "    cdl_raster = first_raster_CDL.ReadAsArray()#*mask\n",
    "    cdl_raster =  cdl_raster.astype(np.float32)\n",
    "    cdl_raster.astype(np.float32)\n",
    "    print(cdl_raster.shape)\n",
    "\n",
    "    CDL_geotransform = first_raster_CDL.GetGeoTransform()\n",
    "    CDL_xres = CDL_geotransform[1]\n",
    "    CDL_yres = -CDL_geotransform[5]\n",
    "    CDL_xmin = CDL_geotransform[0]\n",
    "    CDL_ymax = CDL_geotransform[3]\n",
    "    CDL_spatialref = first_raster_CDL.GetProjectionRef()\n",
    "\n",
    "    plt.rcParams['figure.figsize'] = (20,5);\n",
    "    plt.imshow(cdl_raster,cmap=cdl_cmap,interpolation='nearest');\n",
    "    plt.colorbar(fraction=0.046*cdl_raster.shape[0]/cdl_raster.shape[1],pad=0.04);\n",
    "    plt.ylabel('Y Coordinates (meters)', labelpad=10)\n",
    "    plt.xlabel('X Coordinates (meters)', labelpad=10)\n",
    "    plt.title('Cropland Data Layer');\n",
    "\n",
    "    del first_raster_CDL\n",
    "\n",
    "    ##The image might look a little busy because of the number of classes in the layer\n",
    "else:\n",
    "    print('%s is specified as the training/validation source' %(training_data_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b2a183-990c-4997-bb71-f4fc5a0abd82",
   "metadata": {},
   "source": [
    "## 4.2 &emsp; Identifying Crop pixels in the CDL\n",
    "\n",
    "Creating a binary crop/non-crop classification from the CDL classified classes.\n",
    "\n",
    "Crop classified to 1\n",
    "\n",
    "Non-crop classified to 0\n",
    "\n",
    "This can be customized by study area and what land use types are present there. \n",
    "To make a land class classified as non-crop simply place a \"#\" infront of the line of code for that land cover.\n",
    "\n",
    "In the code that follows, these are assigned one-by-one according the to various index indicators that are part of the CDL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e348f65-68d3-46fd-90f0-0b18df424b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_data_type == 'CDL':\n",
    "    CDL_crop = np.copy(cdl_raster)\n",
    "    unique = np.unique(cdl_raster)\n",
    "    uniquecount = len(unique)\n",
    "\n",
    "    # Get Crop names and ids\n",
    "    # Column 0 = Crop ID\n",
    "    # Column 1 = Crop Name\n",
    "    # Column 2 = Classification number (1 = crop 0 = not crop)\n",
    "\n",
    "    crop_ids = pd.read_csv(ancillary_dir / 'crop_ids.csv',header = None)\n",
    "    # Set all crop classification values equal to 1 \n",
    "    for i in tqdm(crop_ids[0]):\n",
    "        CDL_crop[np.where(cdl_raster == i)] = crop_ids[crop_ids[0] == i][2]\n",
    "    tqdm.write(\"✅ Success!\")\n",
    "else:\n",
    "    print('%s is specified as the training/validation source' %(training_data_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02f1752-783c-4ccf-a874-f2e631683cbb",
   "metadata": {},
   "source": [
    "## 4.3 &emsp; Image of the Crop/Non-Crop classification based on the CDL\n",
    "Below is the resulting clasification image of Crop versus Non-Crop based on the input Cropland Data Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bbc790-5c4b-47ee-b776-ca2f33bedf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all non-crop values to 0 based on assumming that everything not previously classified as crop is non-crop\n",
    "if training_data_type == 'CDL':\n",
    "    crop_binary = np.copy(CDL_crop)\n",
    "    crop_binary[np.where(CDL_crop!= 1)] = 0\n",
    "\n",
    "    fig, ax= plt.subplots(figsize=(20,5))\n",
    "    fig.tight_layout()\n",
    "    binary_cmap = plt.cm.colors.ListedColormap([\"#ffffff\", \"#EDB218\"])\n",
    "    cax = ax.imshow(crop_binary, interpolation='nearest', cmap=binary_cmap)\n",
    "    ax.set_title(\"Crop/Non Crop Classification based on CDL\")\n",
    "    cbar = fig.colorbar(cax, ticks = [0,1], fraction = 0.046 * crop_binary.shape[0] / crop_binary.shape[1], pad = 0.04)\n",
    "    cbar.ax.set_yticklabels(['Non-Crop', 'Crop'])\n",
    "    plt.ylabel('Y Coordinates (meters)', labelpad = 10)\n",
    "    plt.xlabel('X Coordinates (meters)', labelpad = 10)\n",
    "    print('Crop pixels marked as white (value of 1.0)')\n",
    "else:\n",
    "    print('%s is specified as the training/validation source' %(training_data_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16081a3-8d3a-4c90-b8a7-b9f19f1346f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_data_type == 'CDL':\n",
    "    #getting the number of pixels classified as crop and non-crop including the removal of masked pixels\n",
    "    cropcount = np.count_nonzero(crop_binary == 1)\n",
    "    print(\"Number of crop pixels:\", cropcount)\n",
    "\n",
    "    noncount = np.count_nonzero(crop_binary == 0)- rcs111\n",
    "    print(\"Number of non-crop pixels:\",noncount)\n",
    "\n",
    "    #finding the percent of pixels classified as crop and non-crop including the removal of masked pixels\n",
    "    percent_crop_nonmasked_calc = round((cropcount / rcs0) * 100, 2)\n",
    "    print (\"% Crop: \", percent_crop_nonmasked_calc)\n",
    "\n",
    "    percent_noncrop_nonmasked_calc = round((noncount / rcs0) * 100, 2)\n",
    "    print (\"% Non-crop: \", percent_noncrop_nonmasked_calc)\n",
    "else:\n",
    "    print('%s is specified as the training/validation source' %(training_data_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36ae184-a74c-4ec7-90be-174176890ed6",
   "metadata": {},
   "source": [
    "## 4.5 &emsp; Import external validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25321c87-0de9-4da9-bfc6-a111749b416c",
   "metadata": {},
   "source": [
    "In cases where the CDL is not avaliable and / or the an external validation data source is perferred, the user can upload the data here. \n",
    "> **Note:** The external validation data should ideally take form of crop/non-crop polygons as a geojson file, where crop polygons are assigned a value of 1, non-crop polygons a value of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4da789-082b-4ed4-9f28-a9fe13297394",
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_data_type == 'EXTERNAL SOURCE':\n",
    "    file = input(\"provide full filepath of crop/non-crop geojson file:\")\n",
    "    filename = (file.split('/')[-1])\n",
    "else:\n",
    "     print('%s is specified as the training/validation source' %(training_data_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ba7272-fb5c-47e9-8369-1b0cff0b1f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if training_data_type == 'EXTERNAL SOURCE':\n",
    "    file = input(\"provide full filepath of crop/non-crop geojson file:\")\n",
    "    filename= (file.split('/')[-1])\n",
    "\n",
    "    try:\n",
    "        rasterized2 = gdal.Rasterize(crop_dir/filename.replace('geojson','tif'), file, format = 'GTIFF',  creationOptions = [\"COMPRESS=DEFLATE\"], \n",
    "                                     noData = 2, xRes=20, outputType = gdal.GDT_Int16,\n",
    "                                     yRes = 20,allTouched=False,attribute ='id')\n",
    "\n",
    "\n",
    "        rasterized2 = None\n",
    "        tqdm.write('✅ Validation polygons sucessfully rasterized ')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print('An error occured: {e}')\n",
    "else:\n",
    "     print('%s is specified as the training/validation source' %(training_data_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af099660-6934-4dc3-a266-d3503b712744",
   "metadata": {},
   "source": [
    "### Tap the rasterized training polygons to ensure extent and pixel alignment with the CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18ff326-7ce6-4a71-ae6f-7d9ff94b5196",
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_data_type == 'EXTERNAL SOURCE':\n",
    "\n",
    "    updated_fn= str(crop_dir/filename.replace('geojson','tif'))\n",
    "    updated_fn2= str(updated_fn[:-4]+'_corr.tif')\n",
    "    os.system('gdalwarp -overwrite -srcnodata 2 -dstnodata 2 -tap -tr %s %s -te %s %s %s %s %s %s' \n",
    "              %(transform[0], transform[0], ds_x[0][0],ds_y[0][-1],ds_x[0][-1],ds_y[0][0],updated_fn,crop_dir/updated_fn2))\n",
    "\n",
    "else:\n",
    "    print('%s is specified as the training/validation source' %(training_data_type))                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6b5e08-121a-4437-8976-b946dfb0f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_data_type == 'EXTERNAL SOURCE':\n",
    "    crop_binary= gdal.Open(crop_dir/updated_fn2).ReadAsArray()\n",
    "    print(crop_binary.shape)\n",
    "     # clean up un-tapped files (tifs) \n",
    "    os.system('rm -r %s'%(updated_fn))\n",
    "\n",
    "    plt.rcParams['figure.figsize'] = (8,16)\n",
    "    plt.imshow(crop_binary,vmin=0,vmax=2,cmap='viridis');\n",
    "    # 2 is background, 0 is non-crop, 1 is crop\n",
    "    plt.colorbar(ticks = [0, 1, 2],fraction=0.045*crop_binary.shape[0]/crop_binary.shape[1],pad=0.04);\n",
    "    plt.title('Crop/non-crop polygons (Validation): 0 non-crop, 1 crop, 2 background')\n",
    "    \n",
    "else:\n",
    "    print('%s is specified as the training/validation source' %(training_data_type))                            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70737223-bb32-4633-b0ae-abe58bbcbb0b",
   "metadata": {},
   "source": [
    "## 4.6 &emsp; A statistical summary of the number of Crop and Non-crop polygons form external validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6e79e1-4ccf-4a2a-8d30-612263177c61",
   "metadata": {},
   "source": [
    "finding the breakdown of crop/non-crop pixels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae5a17e-b288-422b-9d56-113879fc0dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_data_type == 'EXTERNAL SOURCE':\n",
    "    cropcount_val = np.count_nonzero(crop_binary == 1)\n",
    "    print(\"Number of crop pixels:\", cropcount_val)\n",
    "\n",
    "    noncount_val= np.count_nonzero(crop_binary == 0)\n",
    "    print(\"Number of non-crop pixels:\", noncount_val)\n",
    "\n",
    "    # Percent of pixels classified as crop and non_crop based on Polygons (Validation)\n",
    "\n",
    "    pol0_val = cropcount_val + noncount_val\n",
    "\n",
    "    percent_crop_val = round((cropcount_val / pol0_val)*100, 2)\n",
    "    print(\" % Crop:\", percent_crop_val)\n",
    "\n",
    "    percent_noncrop_val = round((noncount_val / pol0_val)*100, 2)\n",
    "    print(\"% Non-Crop:\", percent_noncrop_val)\n",
    "else:\n",
    "     print('%s is specified as the training/validation source' %(training_data_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd845b9-e6bb-4a37-9664-45621301912f",
   "metadata": {},
   "source": [
    "## 5 &emsp; Getting Accuracy Statistics for the Youden's Index Optimal Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f66fb05-421e-4d13-b3c3-01cb70926831",
   "metadata": {},
   "source": [
    "##### Objectives: \n",
    "1. Create a crop/non-crop classification based on the Youden's Index optimal threshold (section 2.1) \n",
    "2. Return the J-statistic for the determined threshold (maximum difference value between TPR and FPR ranging between 0 and 1)\n",
    "3. Get percent crop and non-crop classified correctly and incorrectly\n",
    "4. Get User's and Producer's accuracy of the classification for both crop and non-crop classes\n",
    "5. Calculate the Kapppa Coefficient = the measure of the agreement between the SAR imagery derived classification and the CDL\n",
    "   - Kappa = (total pixel x total correct pixel - sum of the products)/(total pixel^2 - sum of products)\n",
    "   - Sum of products = sum of row total x column total\n",
    "   - Interpreting Kappa Statistic:\n",
    "       - < 0.20 = Poor agreement \n",
    "       - 0.20 - 0.40     = Fair agreement \n",
    "       - 0.40 - 0.60     = Moderate agreement \n",
    "       -  0.60 - 0.80     = Good agreement \n",
    "       - 0.80 - 1.00     = Very good agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46998ce-a727-43c4-9afa-64808c209a57",
   "metadata": {},
   "source": [
    "Objectives: \n",
    "1. Create a crop/non-crop classification based on the Youden's Index optimal threshold (section 2.1) \n",
    "2. Return the J-statistic for the determined threshold (maximum difference value between TPR and FPR ranging between 0 and 1)\n",
    "3. Get percent crop and non-crop classified correctly and incorrectly\n",
    "4. Get User's and Producer's accuracy of the classification for both crop and non-crop classes\n",
    "5. Calculate the Kapppa Coefficient = the measure of the agreement between the SAR imagery derived classification and the CDL\n",
    "   - Kappa = (total pixel x total correct pixel - sum of the products)/(total pixel^2 - sum of products)\n",
    "   - Sum of products = sum of row total x column total\n",
    "   - Interpreting Kappa Statistic:\n",
    "       - < 0.20 = Poor agreement \n",
    "       - 0.20 - 0.40     = Fair agreement \n",
    "       - 0.40 - 0.60     = Moderate agreement \n",
    "       -  0.60 - 0.80     = Good agreement \n",
    "       - 0.80 - 1.00     = Very good agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ffccb0-63e4-4523-b35f-bbd4469b7395",
   "metadata": {},
   "source": [
    "### Read in true positive and false positive arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d6f772-98cf-49fd-9f2a-7aee04b0698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    TPR_FPR_arrs = np.load(str(TMP_dir/'TPR_FPR_arrs.npz'))\n",
    "    tpr = TPR_FPR_arrs['TPR']\n",
    "    fpr = TPR_FPR_arrs['FPR']\n",
    "    tqdm.write('✅ Success!')\n",
    "except Exception as e:\n",
    "    print('An error occured: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301358d8-93ec-4ad5-9248-0fc4c575a377",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds= list(np.linspace(0,99,100)/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8204f3c5-3e67-4373-a24b-7f9b29ee4455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify image using the Youden's Index Optimal Threshold\n",
    "try: \n",
    "    CVideal_water = np.subtract(CV_reclass_ideal, watermask)\n",
    "    CVideal_crop_non = np.copy(CVideal_water)\n",
    "    CVideal_crop_non[np.where(CVideal_crop_non > 0)] = 1\n",
    "    CVideal_crop_non[np.where(CVideal_crop_non <= 0)] = -10\n",
    "    CV_ideal = np.subtract(crop_binary, CVideal_crop_non)\n",
    "    tqdm.write('✅ Success!')\n",
    "except Exception as e:\n",
    "    print(f\"An error occured: {e}\")\n",
    "\n",
    "# Determining the J-statistic calculated by finding the maximum difference between the TPR and FPR\n",
    "j_scores = tpr-fpr\n",
    "j_ordered = sorted(zip(j_scores,thresholds))\n",
    "j_statistic = (np.round(j_ordered[-1][0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e481e106-a737-423d-815b-2548edceac95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('statistics of accuracy of using CV to classify crop vs non crop based on', training_data_type)\n",
    "if training_data_type == \"CDL\":\n",
    "    \n",
    "    p_crop_correct = np.count_nonzero(CV_ideal == 0)/(rcs0)\n",
    "    p_crop_correct1 = (round((p_crop_correct*100), 2))\n",
    "    print ('% correct crop: ',p_crop_correct1)\n",
    "    p_non_correct = (np.count_nonzero(CV_ideal == 10) - rcs111)/(rcs0)\n",
    "    p_non_correct = (np.count_nonzero(CV_ideal == 10))/(rcs0)\n",
    "    p_non_correct1 = (round((p_non_correct)*100, 2))\n",
    "    print ('% correct non-crop: ', p_non_correct1)\n",
    "    p_crop_incorrect = np.count_nonzero(CV_ideal == 11)/(rcs0)\n",
    "    p_crop_incorrect1 = (round((p_crop_incorrect)*100, 2))  \n",
    "    print ('% incorrect crop: ', p_crop_incorrect1)\n",
    "    p_non_incorrect = np.count_nonzero(CV_ideal == -1)/(rcs0)\n",
    "    p_non_incorrect1 = (round((p_non_incorrect)*100, 2))    \n",
    "    print ('% incorrect non-crop: ', p_non_incorrect1)\n",
    "\n",
    "if training_data_type == \"EXTERNAL SOURCE\":\n",
    "    p_crop_correct = np.count_nonzero(CV_ideal == 0)/(pol0_val)\n",
    "    p_crop_correct1 = (round((p_crop_correct*100),2))\n",
    "    print ('% correct crop: ',p_crop_correct1)\n",
    "    p_non_correct = (np.count_nonzero(CV_ideal == 10)) /(pol0_val)\n",
    "    p_non_correct = (np.count_nonzero(CV_ideal == 10))/(pol0_val)\n",
    "    p_non_correct1 = (round((p_non_correct)*100, 2))\n",
    "    print ('% correct non-crop: ', p_non_correct1)\n",
    "    p_crop_incorrect = np.count_nonzero(CV_ideal == 11)/(pol0_val)\n",
    "    p_crop_incorrect1 = (round((p_crop_incorrect)*100, 2))  \n",
    "    print ('% incorrect crop: ', p_crop_incorrect1)\n",
    "    p_non_incorrect = np.count_nonzero(CV_ideal == -1)/(pol0_val)\n",
    "    p_non_incorrect1 = (round((p_non_incorrect)*100, 2))    \n",
    "    print ('% incorrect non-crop: ', p_non_incorrect1)\n",
    "\n",
    "# Getting Overall Accuracy statistics of the CV classification using Youden's Index optimal threshold based on classification from training data type\n",
    "print ('\\nStatistics of overall accuracy of using CV to classify crop vs non-crop based on', training_data_type)\n",
    "p_overall_correct = round((p_crop_correct + p_non_correct)*100, 2)\n",
    "print ('% overall correct: ', p_overall_correct)\n",
    "p_overall_incorrect = round((p_crop_incorrect + p_non_incorrect)*100, 2)\n",
    "print ('% overall incorrect: ', p_overall_incorrect)\n",
    "\n",
    "# Getting user's and producer's accuracy of the CV classification based on CDL classifications\n",
    "print ('\\nUsers and producers accuracy statistics:')\n",
    "crop_correct = np.count_nonzero(CV_ideal == 0)\n",
    "non_correct = np.count_nonzero(CV_ideal == 10)\n",
    "crop_incorrect = np.count_nonzero(CV_ideal == 11)\n",
    "non_incorrect = np.count_nonzero(CV_ideal == -1)\n",
    "\n",
    "crop_producers_total = crop_correct + crop_incorrect\n",
    "crop_users_total = crop_correct + non_incorrect\n",
    "\n",
    "if training_data_type == \"CDL\":\n",
    "    non_producers_total = (non_correct - rcs111) + non_incorrect\n",
    "    non_users_total = (non_correct - rcs111) + crop_incorrect\n",
    "    crop_p_accuracy = round((crop_correct/crop_producers_total)*100, 2)\n",
    "    print ('% crop producers accuracy: ', crop_p_accuracy)\n",
    "    non_p_accuracy = round(((non_correct - rcs111)/non_producers_total)*100, 2)\n",
    "    print('% non-crop producers accuracy: ', non_p_accuracy)\n",
    "    crop_u_accuracy = round((crop_correct/crop_users_total)*100, 2)\n",
    "    print ('% crop users accuracy: ', crop_u_accuracy)\n",
    "    non_u_accuracy = round(((non_correct - rcs111)/non_users_total)*100, 2)\n",
    "    print ('% non-crop users accuracy: ', non_u_accuracy)\n",
    "\n",
    "if training_data_type == \"EXTERNAL SOURCE\": \n",
    "    non_producers_total= non_correct + non_incorrect\n",
    "    non_users_total= non_correct + crop_incorrect\n",
    "    crop_p_accuracy= round((crop_correct/crop_producers_total)*100,2)\n",
    "    print ('% crop producers accuracy: ', crop_p_accuracy)\n",
    "    non_p_accuracy= round((non_correct/non_producers_total)*100,2)\n",
    "    print('% non-crop producers accuracy:', non_p_accuracy)\n",
    "    crop_u_accuracy= round((crop_correct/crop_users_total)*100,2)\n",
    "    print('% crop users accuracy:', crop_u_accuracy)\n",
    "    non_u_accuracy= round((non_correct/non_users_total)*100,2)\n",
    "    print('% non-crop users accuracy:', non_u_accuracy)\n",
    "\n",
    "# calcuating Kappa Coefficient\n",
    "\n",
    "if training_data_type == \"CDL\":\n",
    "    Total_correct = np.count_nonzero(CV_ideal == 0) + (np.count_nonzero(CV_ideal == 10) - rcs111)\n",
    "    Total_pixel_count = (rcs0)\n",
    "    Sum_of_products_crop_row = np.count_nonzero(CV_ideal == 0) + np.count_nonzero(CV_ideal == -1)\n",
    "    Sum_of_products_non_row = (np.count_nonzero(CV_ideal == 10) - rcs111) + np.count_nonzero(CV_ideal == 11)\n",
    "    Sum_of_products_crop_col = np.count_nonzero(CV_ideal == 0) + np.count_nonzero(CV_ideal == 11)\n",
    "    Sum_of_products_non_col = (np.count_nonzero(CV_ideal == 10) - rcs111) + np.count_nonzero(CV_ideal == -1)\n",
    "\n",
    "if training_data_type == \"EXTERNAL SOURCE\":\n",
    "    Total_pixel_count= (pol0_val)\n",
    "    Total_correct = np.count_nonzero(CV_ideal== 0) + (np.count_nonzero(CV_ideal == 10))\n",
    "    sum_of_products_crop_row = np.count_nonzero(CV_ideal == 0) + np.count_nonzero(CV_ideal == -1)\n",
    "    Sum_of_products_non_row = (np.count_nonzero(CV_ideal == 10)) + np.count_nonzero(CV_ideal== 11)\n",
    "    Sum_of_products_crop_col = np.count_nonzero(CV_ideal == 0) + np.count_nonzero(CV_ideal == 11)\n",
    "    Sum_of_products_non_col = (np.count_nonzero(CV_ideal == 10)) + np.count_nonzero(CV_ideal == -1)\n",
    "\n",
    "Sum_of_products = (Sum_of_products_crop_row * Sum_of_products_crop_col) + (Sum_of_products_non_row * Sum_of_products_non_col)\n",
    "\n",
    "Kappa_coefficient = round((Total_pixel_count * Total_correct - Sum_of_products) / (Total_pixel_count * Total_pixel_count - Sum_of_products), 2)\n",
    "print ('\\nKappa Coefficient: ', Kappa_coefficient)\n",
    "if Kappa_coefficient <= 0.2:\n",
    "    print ('Poor agreement')\n",
    "else:\n",
    "    if Kappa_coefficient <= 0.4:\n",
    "        print ('Fair agreement')\n",
    "    else:\n",
    "        if Kappa_coefficient <= 0.6:\n",
    "            print ('Moderate agreement')\n",
    "        else: \n",
    "            if Kappa_coefficient <= 0.8:\n",
    "                print ('Good agreement')\n",
    "            else: \n",
    "                if Kappa_coefficient > 0.8:\n",
    "                    print ('Very good agreement')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa28e46-427f-438f-984d-f9f41feed6d0",
   "metadata": {},
   "source": [
    "##  &emsp; Export Accuracy Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1742feee-cfae-4261-816c-a65a808058bd",
   "metadata": {},
   "source": [
    "Writes the calculated accuracy results to an excel CSV file to the set output directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466dcd33-fda9-4a1b-a657-a3867929a9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_results = \"NISAR_L3_%s_40_A_CROP_%s_%s_%s_001_%s_accuracy_statistics.csv\" %(str(which_pol[:-2]), l3_start_date, l3_end_date, aoi_prefix, today)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80882888-251e-4c3f-a9a0-961dd9f0cd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting accuracy statistics as a CSV file\n",
    "\n",
    "l0 = [best_thresh]\n",
    "l1 = [p_overall_correct]\n",
    "l2 = [p_crop_correct1]\n",
    "l3 = [p_non_correct1]\n",
    "l4 = [p_crop_incorrect1]\n",
    "l5 = [p_non_incorrect1]\n",
    "l6 = [crop_p_accuracy]\n",
    "l7 = [non_p_accuracy]\n",
    "l8 = [crop_u_accuracy]\n",
    "l9 = [non_u_accuracy]\n",
    "l10 = [Kappa_coefficient]\n",
    "l11 = [j_statistic]\n",
    "\n",
    "\n",
    "df = pd.DataFrame({\"Threshold\": l0, \"Overall Correct\": l1, \"% crop correct\": l2, \"% non-crop correct\": l3, \"% crop incorrect\": l4, \"% non-crop incorrect\": l5, \"% Crop Producers Accuracy\": l6, \"% Non-crop Producers Accuarcy\": l7, \"% Crop Users Accuracy\":l8, \"% Non-crop Users Accuracy\": l9, \"Kappa Coefficient\": l10, \"J-statistic\": l11})\n",
    "\n",
    "df.to_csv(str(aoi_dir / Accuracy_results))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939bf29a-2ff7-4e58-ac48-4543f15c7826",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<a id=\"SEC_6\"></a>\n",
    "# 6 &emsp; References\n",
    "\n",
    "1.\tWhelen, T. and P. Siqueira, “A Multi-season Study of L-band UAVSAR Observations for Agricultural Fields in the San Joaquin Valley,” Rem. Sens. Env., 193, 216-224, https://doi.org/10.1016/j.rse.2017.03.014, 2017.\n",
    "\n",
    "2.\tWhelen, T. and P. Siqueira, “Time-series agricultural classification of Sentinel-1 data over North Dakota,” Rem. Sens. Lett., 9(5), 411-420, https://doi.org/10.1080/2150704X.2018.1430393, 2018.\n",
    "\n",
    "3.\tWhelen, T. and P. Siqueira, “Coefficient of variation for use in crop area classification across multiple climates,” Int. J. Appl. Earth. Obs. & Geoinf., 67, 114-122, https://doi.org/10.1016/j.jag.2017.12.014, 2018.\n",
    "\n",
    "4.\tKraatz, S., N. Torbick, X. Jiao, X. Huang, L.D. Robertson, A. Davidson, H. McNairn, M.H. Cosh, P. Siqueira, “Comparison between Dense L-Band and C-Band Synthetic Aperture Radar (SAR) Time Series for Crop Area Mapping over a NISAR Calibration-Validation Site,” Agronomy. 11(2), https://doi.org/10.3390/agronomy11020273, 2021.\n",
    "\n",
    "5.\tKraatz, S., S. Rose, M. Cosh, N. Torbick, X. Huang, & P. Siqueira, “Performance evaluation of UAVSAR and simulated NISAR data for crop/noncrop classification over Stoneville, MS.” Earth and Space Sci, 8(1), e2020EA001363. https://doi.org/10.1029/2020EA001363, 2021\n",
    "\n",
    "6.\tRose, S., S. Kraatz, J. Kellndorfer, M.H. Cosh, N. Torbick, X. Huang, and P. Siqueira, “Evaluating NISAR's cropland mapping algorithm over the conterminous United States using Sentinel-1 data,” Rem. Sens. Env., 260, 112472, https://doi.org/10.1016/j.rse.2021.112472, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f7d703-ef8b-4f5d-9a36-3282f1205090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
